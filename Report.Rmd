---
title: "Project Report"
author: "Team: Charline Gu (jg4891), Yaxuan Deng (yd2810), Yuanyuan Zhang (yz4982), Wen Li (wl3013)"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

<style>
h4.author {
  font-size: 12px;
  font-weight: 400;
  color: #777777;
}
</style>


***
## Motivation
In 2023, healthcare spending in the United States accounted for 17.6% of the national GDP, totaling approximately $4.9 trillion. Despite this immense expenditure, millions of Americans continue to struggle with chronic diseases, and healthcare delivery remains highly fragmented. This inefficiency not only strains the system financially but also results in poorer outcomes for those who need care the most. One of the central challenges is the “hot spotters” problem—a small subset of patients who incur the highest costs often receive the least coordinated and least effective care. Understanding who these patients are, what conditions they have, and how their costs evolve over time is critical for developing targeted interventions that improve health outcomes while reducing unnecessary spending.
Motivated by these challenges, this project aims to analyze the relationship between healthcare costs and medical conditions to uncover patterns among high-cost patients. By identifying key demographic and clinical characteristics associated with elevated healthcare spending, we aim to inform strategies for more effective resource allocation and more integrated models of care.


***
## Related Work
Our project is largely inspired by [Mitchell’s MEPS Statistical Brief](https://meps.ahrq.gov/data_files/publications/st546/stat546.shtml). Following this brief provides us with a well-established methodological framework for defining high-expenditure groups, characterizing their demographic and clinical profiles, and decomposing spending by service type and payer. By using this approach, we ensure that our analysis is methodologically sound, comparable to prior work, and capable of producing interpretable population-level insights.
In addition, we draw on tools and techniques introduced in class, particularly for interactive visualization. Our interactive dashboard is implemented using R Shiny dashboard, which allows users to explore expenditure groups, demographics, and condition categories in a more intuitive and accessible way.

***
## Initial Question

We initially aimed to answer the following key questions:

1. Who are the patients that incur the highest healthcare expenditures in 2023 (top 1%, top 5%, top 10%) within the U.S. as captured by MEPS?

2. What demographic and socioeconomic characteristics are associated with being high-cost?

3. Using CCSR classification, what is the role of multimorbidity and major chronic conditions in predicting whether someone is high-cost?

During the process of analysis, our questions became more concrete. For example, we extend from descriptive to predictive framing, exploring how well we can predict whether a person is high-cost using demographics, income/poverty, insurance, and multimorbidity. In addition, while generating descriptive statistics, we realized that many patterns were more easily understood when visualized interactively. This led us to develop a **Shiny dashboard**, allowing users to:

   - select age group, insurance, and sex
   - dynamically view expenditure distributions
   - compare demographic subgroups and explore how spending varies across key characteristics

Throughout the modeling and exploratory analysis process, several deeper questions arose. We started to think about what is the practical value of the predictive model. Even if certain variables  statistically improve prediction of high-cost status, does the model improve enough to matter for policy or care management? Our cross-validated RMSE comparison across baseline, full, and selected models pushed us to reflect on whether the added complexity yields meaningful practical improvement. But since the prevalence of `high-cost` is too low and noises exist, how to make such predictions practically meaningful remains an open question.

Together, these new questions extend our original motivation of understanding “who” the high-cost patients are toward how we might use routinely available information (demographics, income, insurance, diagnoses) to identify and prioritize them for targeted interventions.

***
## Data sources and access

Our analysis uses publicly available data from the Medical Expenditure Panel Survey (MEPS), conducted by the Agency for Healthcare Research and Quality (AHRQ). Specifically, we draw on two 2023 public-use files:

- **2023 Full-Year Consolidated Data File (HC-251)**  
  This file provides person-level information on annual health care expenditures, demographics, insurance coverage, and survey design variables for the U.S. civilian noninstitutionalized population.

- **2023 Medical Conditions File (HC-249)**  
  This file contains encounter-level information on medical conditions reported during MEPS interviews, including condition identifiers and Clinical Classifications Software Refined (CCSR) codes.

Both files were downloaded from the MEPS website as standardized `.ssp` files. We imported them into R using the `MEPS` R package and the `read_MEPS()` function, which implements the recommended MEPS data-reading workflow and preserves variable formats. For convenience in downstream analysis, we converted all variable names to lowercase immediately after import.

<br>

### Unit of analysis and key variables

The primary unit of analysis in this project is the **individual (person)**. From the full-year consolidated file (HC-251), we retain:

- **Survey design variables**
  - `varstr`, `varpsu`: variance strata and primary sampling unit identifiers  
  - `perwt23f`: person-level survey weight  

- **Expenditure variable**
  - `totexp23`: total health care expenditures in 2023, summing all payments from all payers and service types at the person level  

- **Core demographic and socioeconomic variables**
  - `agelast`: age at the end of 2023  
  - `sex`: sex (1 = male, 2 = female)  
  - `racethx`: detailed race/ethnicity categories  
  - `povcat23`: family income relative to the federal poverty line (1–5)  
  - `inscov23`: insurance coverage category (1 = any private, 2 = public only, 3 = uninsured)  

From the conditions file (HC-249), we retain:

- **Linkage and survey design variables:** `dupersid`, `condidx`, `varstr`, `varpsu`, `perwt23f`  
- **Condition classification:** CCSR codes (`ccsr1x`–`ccsr4x`), which we later collapse to a single primary condition code per record.

These variables form the basis for defining high-cost groups, describing population characteristics, and identifying the most commonly treated conditions among high-expenditure patients.

<br>

### Cleaning and preparation of the person-level file (HC-251)

We begin by creating a working copy of the full-year consolidated file and applying several cleaning steps:

1. **Restriction to positive weights**  
   MEPS uses person-level weights to represent the target population. We restrict the analytic dataset to records with `perwt23f > 0`, which excludes ineligible or unweighted respondents and ensures that weighted estimates correspond to the 2023 U.S. civilian noninstitutionalized population.

2. **Standardizing missing values**  
   MEPS encodes various types of missing or inapplicable responses using negative numeric codes (e.g., -1, -7, -8, -9, -15). To avoid treating these codes as valid values in summaries or models, we loop over all numeric variables and recode these negative codes to `NA`. This harmonized missing-value convention allows base R and `survey` functions to automatically exclude missing observations when computing estimates.

3. **Variable selection**  
   To keep the working dataset focused and efficient, we subset to a minimal set of variables required for our analyses: the person identifier (`dupersid`), survey design variables, `totexp23`, and the demographic and socioeconomic variables listed above. This curated dataset (`fyc23_clean`) is used to construct the survey design object and all subsequent person-level analyses.

4. **Re-defining the survey design**  
   After cleaning and subsetting, we reconstruct a survey design object using the `survey` package, specifying:
   - clustering by `varpsu`  
   - stratification by `varstr`  
   - weighting by `perwt23f`  
   - `nest = TRUE` to correctly reflect the multi-stage design  

   All weighted estimates in the project—such as proportions, means, and quantiles—are computed under this survey design.

<br>

### Construction of demographic and socioeconomic categories

For descriptive and stratified analyses, we recode several MEPS variables into interpretable categorical factors:

- **Age groups (`age_cat4`)**  
  We categorize `agelast` into four life-stage groups commonly used in health services research:
  - 0–17 years  
  - 18–44 years  
  - 45–64 years  
  - 65 years and older  

  The factor is explicitly ordered from youngest to oldest to facilitate interpretation of age patterns.

- **Sex (`sex_f`)**  
  We recode `sex` into a labeled factor with levels **“Male”** and **“Female”**, matching the original coding (1 and 2, respectively).

- **Race/ethnicity (`race4`)**  
  Using `racethx`, we construct a four-category race/ethnicity variable:
  - Hispanic  
  - Non-Hispanic White (NH White)  
  - Non-Hispanic Black (NH Black)  
  - Non-Hispanic Asian/Other (NH Asian/Other), combining smaller non-White, non-Black race categories to improve stability of estimates  

  The reference level is set to NH White, which is consistent with many MEPS reports and facilitates interpretation of racial/ethnic comparisons.

- **Income relative to poverty (`povcat_f`)**  
  `povcat23` (1–5) is recoded into labeled categories:
  - Poor  
  - Near-poor  
  - Low income  
  - Middle income  
  - High income  

  Note that “High income” in MEPS corresponds to family income ≥ 4 times the federal poverty line; this group primarily represents middle-class and above rather than the extremely wealthy.

- **Insurance coverage (`inscov_f`)**  
  We recode `inscov23` into:
  - Any private insurance  
  - Public insurance only  
  - Uninsured  

After creating these factors, we reconstruct the survey design object so that all downstream analyses use the updated categorical variables.

<br>

### Defining expenditure groups (Top 1%, Top 5%, Top 10%, Bottom 50%)

Following the approach in the MEPS Statistical Brief on the concentration of healthcare expenditures, we use survey-weighted quantiles of `totexp23` to define mutually exclusive expenditure groups:

- Using `svyquantile()` under our survey design, we compute the weighted:
  - 50th percentile (median)  
  - 90th percentile  
  - 95th percentile  
  - 99th percentile  

Letting these cutpoints be \(p_{50}\), \(p_{90}\), \(p_{95}\), and \(p_{99}\), we create a categorical variable `exp_group`:

- **Top 1%**: `totexp23 ≥ p99`  
- **Top 5%**: `p95 ≤ totexp23 < p99`  
- **Top 10%**: `p90 ≤ totexp23 < p95`  
- **Bottom 50%**: `totexp23 ≤ p50`  
- **50–90%**: all remaining individuals with expenditures between the median and the 90th percentile  

The factor is ordered as: Bottom 50%, 50–90%, Top 10%, Top 5%, Top 1%. This structure allows us to align our results with prior MEPS briefs and to focus particularly on the small subset of “high-cost” patients in the Top 1% and Top 5%.

We then reconstruct the survey design once more using `fyc23_clean` with `exp_group` included, enabling direct computation of weighted distributions of demographic and clinical characteristics within each expenditure group.

<br>

### Cleaning and preparation of the conditions file (HC-249)

To study the clinical profile of high-cost patients, we process the 2023 Medical Conditions file as follows:

1. **Standardizing missing values**  
   As in the person file, we convert negative numeric codes (e.g., -1, -7, -8, -9, -15) to `NA` across all numeric variables. For the CCSR code variables (`ccsr1x`–`ccsr4x`), which are stored as character strings, we replace sentinel values such as `"-1"` and `"-15"` with `NA`.

2. **Defining a primary CCSR code (`ccsr_main`)**  
   Each condition record may have up to four CCSR codes. To simplify analysis and ensure that each record is assigned a single primary condition category, we construct `ccsr_main` using a hierarchical rule:
   - Start with `ccsr1x`  
   - If `ccsr1x` is missing, use `ccsr2x`  
   - If still missing, fall back to `ccsr3x`, and then `ccsr4x` if necessary  

   We drop records for which all four CCSR codes are missing so that the conditions dataset only includes observations with a valid clinical classification.

3. **Variable selection**  
   We retain only variables needed for linkage and weighting in later analyses:
   - `dupersid` (person identifier) and `condidx` (condition identifier)  
   - `varstr`, `varpsu`, `perwt23f`  
   - `ccsr_main`  

   This cleaned conditions dataset (`cond23_clean`) can be merged with the person-level dataset by `dupersid`, allowing us to describe the most common CCSR categories among individuals in the Top 1%, Top 5%, and other expenditure groups.

<br>

### Quality checks

To verify the integrity of our cleaned data and survey design, we conduct several diagnostic checks:

- We confirm that the sum of survey weights in the person-level design is on the order of the U.S. population and that the weighted totals by age group, race/ethnicity, poverty category, and insurance status closely match the overall total (up to small rounding differences).  
- We inspect cross-tabulations between original MEPS codes and our recoded factors (e.g., `racethx` vs. `race4`, `povcat23` vs. `povcat_f`, `inscov23` vs. `inscov_f`) to ensure that category mappings are correct.  
- We compute weighted frequencies and proportions for `exp_group` to confirm that the quantile-based cutpoints produce reasonable shares of the population in each expenditure category.

These steps provide confidence that our analytic datasets accurately reflect the intended MEPS design and that our derived variables are correctly constructed. All data cleaning and processing is implemented in R and is fully reproducible in the project code.


### Data cleaning code 

*The full, reproducible code used to implement the cleaning steps described above is provided below. Readers who are primarily interested in results may skip this section.*


<details>
<summary><strong> Click to show / hide full data cleaning and preparation code</strong></summary>

<br>

```{r data-cleaning-full, echo=TRUE, message=FALSE, warning=FALSE}
# Load in packages
library(devtools)
library(tidyverse)
library(readr)
library(readxl)
library(haven)
library(survey)
library(MEPS)
library(knitr)

# Read "2023 MEPS" data
# 2023 Full-Year Consolidated（HC-251）
## Personnel expenses + Demographics + Sampling design variables
fyc23  <- read_MEPS(file = "h251")
cond23 <- read_MEPS(file = "h249")

## Read "2023 Medical Conditions" data（HC-249）
## Diseases / CCSR
names(fyc23)  <- tolower(names(fyc23))
names(cond23) <- tolower(names(cond23))

des23 <- svydesign(
  ids    = ~varpsu,
  strata = ~varstr,
  weights= ~perwt23f,
  data   = fyc23,
  nest   = TRUE
)

# This chunk only need to run in "Console" once, do not run when knitting the file
# devtools::install_github("e-mitchell/meps_r_pkg/MEPS")
# library(MEPS)

# Quick check of the total fee variable (totexp23)
summary(fyc23$totexp23)
names(fyc23)[1:30]
grep("23", names(fyc23), value = TRUE)[1:20]
nrow(fyc23) 

## data clean
fyc23_clean <- fyc23

# Only keep the individuals with positive weight
fyc23_clean <- fyc23_clean[fyc23_clean$perwt23f > 0, ]

# Change all the missing value (-1, -7, -8, -9, -15) into NA
num_vars <- sapply(fyc23_clean, is.numeric)

for (j in which(num_vars)) {
  x <- fyc23_clean[[j]]
  x[x %in% c(-1, -7, -8, -9, -15)] <- NA
  fyc23_clean[[j]] <- x
}

# Only keep the variables needed for this project (could extend later)
keep_vars <- c(
  "dupersid", "panel", "varstr", "varpsu", "perwt23f",
  "totexp23",
  "agelast", "sex", "racethx",
  "povcat23", "inscov23"
)

fyc23_clean <- fyc23_clean[ , keep_vars]

# Use cleaned data to rebuild "survey design"
des23 <- svydesign(
  ids    = ~varpsu,
  strata = ~varstr,
  weights= ~perwt23f,
  data   = fyc23_clean,
  nest   = TRUE
)

## Demographic variables

# 2.1 Build blank variable columns
fyc23_clean$age_cat4  <- NA
fyc23_clean$sex_f     <- NA
fyc23_clean$race4     <- NA
fyc23_clean$povcat_f  <- NA
fyc23_clean$inscov_f  <- NA

# 2.2 Age groups：0–17, 18–44, 45–64, 65+
fyc23_clean$age_cat4[fyc23_clean$agelast <= 17] <- "0-17"
fyc23_clean$age_cat4[fyc23_clean$agelast >= 18 & fyc23_clean$agelast <= 44] <- "18-44"
fyc23_clean$age_cat4[fyc23_clean$agelast >= 45 & fyc23_clean$agelast <= 64] <- "45-64"
fyc23_clean$age_cat4[fyc23_clean$agelast >= 65] <- "65+"

fyc23_clean$age_cat4 <- factor(
  fyc23_clean$age_cat4,
  levels = c("0-17", "18-44", "45-64", "65+")
)

# 2.3 Gender: 1=Male, 2=Female
fyc23_clean$sex_f[fyc23_clean$sex == 1] <- "Male"
fyc23_clean$sex_f[fyc23_clean$sex == 2] <- "Female"
fyc23_clean$sex_f <- factor(
  fyc23_clean$sex_f,
  levels = c("Male", "Female")
)

# 2.4 Race: NH White, NH Black, Hispanic, NH Asian/Other
fyc23_clean$race4[fyc23_clean$racethx == 1] <- "Hispanic"
fyc23_clean$race4[fyc23_clean$racethx == 2] <- "NH White"
fyc23_clean$race4[fyc23_clean$racethx == 3] <- "NH Black"
fyc23_clean$race4[fyc23_clean$racethx %in% c(4, 5)] <- "NH Asian/Other"

fyc23_clean$race4 <- factor(
  fyc23_clean$race4,
  levels = c("NH White", "NH Black", "Hispanic", "NH Asian/Other")
)

# 2.5 Poverty line groups (POVCAT23): 1–5
pov_labels <- c(
  "Poor", "Near-poor", "Low income",
  "Middle income", "High income"
)

fyc23_clean$povcat_f <- factor(
  fyc23_clean$povcat23,
  levels = 1:5,
  labels = pov_labels
)

# 2.6 Insurance type (INSCOV23): 1 any private, 2 public only, 3 uninsured
ins_labels <- c("Any private", "Public only", "Uninsured")

fyc23_clean$inscov_f <- factor(
  fyc23_clean$inscov23,
  levels = 1:3,
  labels = ins_labels
)

# 2.7 Use updated data to rebuild "design"
des23 <- svydesign(
  ids    = ~varpsu,
  strata = ~varstr,
  weights= ~perwt23f,
  data   = fyc23_clean,
  nest   = TRUE
)

# Quick checks
svytable(~ age_cat4, des23)
svytable(~ race4, des23)
svytable(~ povcat_f, des23)
svytable(~ inscov_f, des23)

table(fyc23_clean$age_cat4, useNA = "ifany")
tapply(
  fyc23_clean$agelast,
  fyc23_clean$age_cat4,
  function(x) range(x, na.rm = TRUE)
)
table(fyc23_clean$racethx, fyc23_clean$race4, useNA = "ifany")
table(fyc23_clean$povcat23, fyc23_clean$povcat_f, useNA = "ifany")
table(fyc23_clean$inscov23, fyc23_clean$inscov_f, useNA = "ifany")

# Define Top 1%、Top 5%、Top 10%、Bottom 50%
exp_cuts <- svyquantile(
  ~ totexp23,
  design    = des23,
  quantiles = c(0.50, 0.90, 0.95, 0.99),
  ci        = FALSE
)

exp_cuts
str(exp_cuts)

q_vec <- as.numeric(exp_cuts$totexp23)
p50 <- q_vec[1]
p90 <- q_vec[2]
p95 <- q_vec[3]
p99 <- q_vec[4]

fyc23_clean$exp_group <- NA
fyc23_clean$exp_group[fyc23_clean$totexp23 >= p99] <- "Top 1%"
fyc23_clean$exp_group[fyc23_clean$totexp23 >= p95 & fyc23_clean$totexp23 < p99] <- "Top 5%"
fyc23_clean$exp_group[fyc23_clean$totexp23 >= p90 & fyc23_clean$totexp23 < p95] <- "Top 10%"
fyc23_clean$exp_group[fyc23_clean$totexp23 <= p50] <- "Bottom 50%"

fyc23_clean$exp_group[
  is.na(fyc23_clean$exp_group) & !is.na(fyc23_clean$totexp23)
] <- "50–90%"

fyc23_clean$exp_group <- factor(
  fyc23_clean$exp_group,
  levels = c("Bottom 50%", "50–90%", "Top 10%", "Top 5%", "Top 1%")
)

des23 <- svydesign(
  ids    = ~varpsu,
  strata = ~varstr,
  weights= ~perwt23f,
  data   = fyc23_clean,
  nest   = TRUE
)

svytable(~ exp_group, des23)
svytable(~ exp_group, des23) / sum(weights(des23))

# Handle the data of "cond23"
cond23_clean <- cond23

num_vars_c <- sapply(cond23_clean, is.numeric)
for (j in which(num_vars_c)) {
  x <- cond23_clean[[j]]
  x[x %in% c(-1, -7, -8, -9, -15)] <- NA
  cond23_clean[[j]] <- x
}

ccsr_cols <- grep("^ccsr", names(cond23_clean), value = TRUE)
for (nm in ccsr_cols) {
  x <- cond23_clean[[nm]]
  x[x %in% c("-1", "-15")] <- NA
  cond23_clean[[nm]] <- x
}

cond23_clean$ccsr_main <- cond23_clean$ccsr1x
idx_na <- is.na(cond23_clean$ccsr_main) & !is.na(cond23_clean$ccsr2x)
cond23_clean$ccsr_main[idx_na] <- cond23_clean$ccsr2x[idx_na]
idx_na <- is.na(cond23_clean$ccsr_main) & !is.na(cond23_clean$ccsr3x)
cond23_clean$ccsr_main[idx_na] <- cond23_clean$ccsr3x[idx_na]
idx_na <- is.na(cond23_clean$ccsr_main) & !is.na(cond23_clean$ccsr4x)
cond23_clean$ccsr_main[idx_na] <- cond23_clean$ccsr4x[idx_na]

cond23_clean <- cond23_clean[!is.na(cond23_clean$ccsr_main), ]

keep_cond_vars <- c(
  "dupersid", "condidx",
  "varstr", "varpsu", "perwt23f",
  "ccsr_main"
)
cond23_clean <- cond23_clean[ , keep_cond_vars]

head(sort(table(cond23_clean$ccsr_main), decreasing = TRUE), 10)

# Double checks
total_pop <- sum(weights(des23))
total_pop

tab_age   <- svytable(~ age_cat4,  des23)
tab_race  <- svytable(~ race4,     des23)
tab_pov   <- svytable(~ povcat_f,  des23)
tab_ins   <- svytable(~ inscov_f,  des23)

sum_age  <- sum(tab_age)
sum_race <- sum(tab_race)
sum_pov  <- sum(tab_pov)
sum_ins  <- sum(tab_ins)

c(
  total_pop = total_pop,
  sum_age   = sum_age,
  sum_race  = sum_race,
  sum_pov   = sum_pov,
  sum_ins   = sum_ins
)

c(
  age_minus_total  = sum_age  - total_pop,
  race_minus_total = sum_race - total_pop,
  pov_minus_total  = sum_pov  - total_pop,
  ins_minus_total  = sum_ins  - total_pop
)

tab_age
prop_age <- prop.table(tab_age)
prop_age
sum(prop_age)

tab_race
prop_race <- prop.table(tab_race)
prop_race
sum(prop_race)

tab_pov
prop_pov <- prop.table(tab_pov)
prop_pov
sum(prop_pov)

tab_ins
prop_ins <- prop.table(tab_ins)
prop_ins
sum(prop_ins)

table(fyc23_clean$age_cat4, useNA = "ifany")
tapply(
  fyc23_clean$agelast,
  fyc23_clean$age_cat4,
  function(x) range(x, na.rm = TRUE)
)

table(fyc23_clean$racethx, fyc23_clean$race4, useNA = "ifany")
table(fyc23_clean$povcat23, fyc23_clean$povcat_f, useNA = "ifany")
table(fyc23_clean$inscov23, fyc23_clean$inscov_f, useNA = "ifany")

tab_exp <- svytable(~ exp_group, des23)
tab_exp
prop_exp <- prop.table(tab_exp)
prop_exp
sum(prop_exp)
```
</details>



***
## Demographic Information
```{r include=FALSE}
# 2.2 Age groups：0–17, 18–44, 45–64, 65+
fyc23_clean$age_cat4[fyc23_clean$agelast <= 17] <-
  "0-17"
fyc23_clean$age_cat4[fyc23_clean$agelast >= 18 &
                     fyc23_clean$agelast <= 44] <-
  "18-44"
fyc23_clean$age_cat4[fyc23_clean$agelast >= 45 &
                     fyc23_clean$agelast <= 64] <-
  "45-64"
fyc23_clean$age_cat4[fyc23_clean$agelast >= 65] <-
  "65+"

fyc23_clean$age_cat4 <- factor(
  fyc23_clean$age_cat4,
  levels = c("0-17", "18-44", "45-64", "65+")
)
```

From the age distribution table, among 18463 participants, 19% of individuals age under 17 years old.
30% of participants aged between 18 and 44 years old. About 26% participants age between 45
and 64 years old. 25% of participants aged above 65 years old. 

```{r echo=FALSE}
fyc23_clean %>%
  count(age_cat4) %>%
  rename(`Age Category` = age_cat4) %>%
  mutate(percent = round(n / sum(n) * 100, 1)) %>%
  bind_rows(
    summarize(., `Age Category` = "Total",
                 n = sum(n),
                 percent = round(sum(n) / sum(n) * 100, 1))
  ) %>%
  kable()
```

```{r include=FALSE}
fyc23_clean$sex_f[fyc23_clean$sex == 1] <- "Male"
fyc23_clean$sex_f[fyc23_clean$sex == 2] <- "Female"
fyc23_clean$sex_f <- factor(
  fyc23_clean$sex_f,
  levels = c("Male", "Female")
)
```

We can see that 8783 (47.6%) individuals are male and 9680 (52.4%) individuals are female.
```{r echo=FALSE}
fyc23_clean %>%
  count(sex_f) %>%
  rename(`Sex` = sex_f) %>%
  mutate(percent = round(n / sum(n) * 100, 1)) %>%
  bind_rows(
    summarize(., `Sex` = "Total",
                 n = sum(n),
                 percent = round(sum(n) / sum(n) * 100, 1))
  ) %>%
  kable()
```

```{r include=FALSE}
fyc23_clean$race4[fyc23_clean$racethx == 1] <- "Hispanic"
fyc23_clean$race4[fyc23_clean$racethx == 2] <- "NH White"
fyc23_clean$race4[fyc23_clean$racethx == 3] <- "NH Black"
fyc23_clean$race4[fyc23_clean$racethx %in% c(4, 5)] <- "NH Asian/Other"

fyc23_clean$race4 <- factor(
  fyc23_clean$race4,
  levels = c("NH White", "NH Black", "Hispanic", "NH Asian/Other")
)
```

However, from the race distribution table, it seems that the distribution is not 
equal among white, black, hispanic, asian, and other people. 54.8% participants
are white. 13% are black. 22.1% are hispanic. Asians/other only takes up 9.8% of the 
sample population.

```{r echo=FALSE}
fyc23_clean %>%
  count(race4) %>%
  rename(`Race Category` = race4) %>%
  mutate(percent = round(n / sum(n) * 100, 1)) %>%
  bind_rows(
    summarize(., `Race Category` = "Total",
                 n = sum(n),
                 percent = round(sum(n) / sum(n) * 100, 1))
  ) %>%
  kable()
```

### Interactive Dashboard
We also created an interactive dashboard via rshiny to show the expenditure for each race or sex.
You can zoom in or zoom out by dragging the parts of plot. We created a violin plot to show total
health expenditure in 2023 by 4 age groups and different races, which is in different colors. We 
also created a histogram of number of people in four income levels, near-poor, poor, low-income, 
middle-income, and high-income, grouped by insurance types. In addition, we created a scatterplot to show the health expenditure in 2023 among different insurance types, grouped by sex. 
The interactive dashboard can be accessed at [here](https://jinghg.shinyapps.io/final_projectgithub/).

***
## Additional Analysis

### Survey-Weighted Regression Modeling
To complement our descriptive analyses, we conducted a series of survey-weighted logistic regression models to examine factors associated with being a high-cost individual (defined as the top 5% of total expenditures based on survey-weighted percentiles). 

All models were estimated using the MEPS complex survey design, incorporating strata, PSUs, and person-level weights.

<br>

### Model 1: Baseline demographic and socioeconomic predictors

First, we fit an initial model with 6 predictors:

- age group (`age_cat4`)
- sex (`sex_f`)
- race/ethnicity (`race4`)
- poverty/income category (`povcat_f`)
- insurance coverage (`inscov_f`)
- multimorbidity (`n_ccsr`)

`baseline_formula <- high_cost ~ age_cat4 + sex_f + race4 + povcat_f + inscov_f + n_ccsr`

```{r echo=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(purrr)
library(survey)

# create n_ccsr to record multi-morbidity
person_ccsr <- cond23_clean %>% 
  group_by(dupersid) %>% 
  summarise(
    n_ccsr = n_distinct(ccsr_main),   # number of diseases with different CCSR 
    .groups = "drop"
  ) %>% 
  mutate(
    multi_morbidity = if_else(n_ccsr >= 3, 1, 0)  # threshold can be customized
  )

ccsr_counts <- cond23_clean %>% 
  count(ccsr_main, sort = TRUE)

ccsr_top20 <- ccsr_counts %>% 
  slice_max(n, n = 20)

# recheck using weight
ccsr_w_counts <- cond23_clean %>% 
  group_by(ccsr_main) %>% 
  summarise(
    w_count = sum(perwt23f, na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  arrange(desc(w_count))

ccsr_w_top20 <- ccsr_w_counts %>% 
  slice_max(w_count, n = 20)

ccsr_union <- union(ccsr_counts$ccsr_main[1:10], ccsr_w_counts$ccsr_main[1:10])

ccsr_main_values <- unique(cond23_clean$ccsr_main)

# create binary variable for each ccsr in ccsr_union
for (disease in ccsr_union) {
  var_name <- disease
  # check whether the person has that disease
  person_ccsr[[var_name]] <- ifelse(
    person_ccsr$dupersid %in% cond23_clean$dupersid[cond23_clean$ccsr_main == disease],
    1, 
    0
  )
}

fyc23_model <- fyc23_clean %>%
  left_join(person_ccsr, by = "dupersid") %>% 
  mutate(high_cost = ifelse(exp_group == "Top 5%", 1, 0))
# set outcome variable as 'whether the person is in the top 5% expenses group'
         

des_model <- svydesign(
  ids     = ~varpsu,
  strata  = ~varstr,
  weights = ~perwt23f,
  data    = fyc23_model,
  nest    = TRUE
)
```

```{r echo=FALSE}
# summary(model_baseline)
```

```{r echo=FALSE}
# baseline model
baseline_formula <- high_cost ~ 
  age_cat4 + sex_f + race4 + povcat_f + inscov_f + n_ccsr

model_baseline <- svyglm(
  baseline_formula,
  design = des_model,
  family = quasibinomial()
)

```

```{r echo=FALSE}
# Extract coefficients from baseline model
coef_tab <- summary(model_baseline)$coefficients

# Function: attach significance codes directly to the p-value string
add_sig <- function(p) {
  code <- ifelse(p < 0.001, "***",
          ifelse(p < 0.01, "**",
          ifelse(p < 0.05, "*",
          ifelse(p < 0.1, ".", ""))))
  paste0(format(round(p, 4), nsmall = 4), code)
}

baseline_results <- data.frame(
  Variable  = rownames(coef_tab),
  Estimate  = coef_tab[, "Estimate"],
  P_value   = coef_tab[, "Pr(>|t|)"]
) %>%
  dplyr::filter(Variable != "(Intercept)") %>%
  mutate(
    Pretty = recode(
      Variable,
      "age_cat418-44"         = "Age 18–44",
      "age_cat445-64"         = "Age 45–64",
      "age_cat465+"           = "Age 65+",
      "sex_fFemale"           = "Female",
      "race4NH Black"         = "NH Black",
      "race4Hispanic"         = "Hispanic",
      "race4NH Asian/Other"   = "NH Asian/Other",
      "povcat_fNear-poor"     = "Near-poor",
      "povcat_fLow income"    = "Low income",
      "povcat_fMiddle income" = "Middle income",
      "povcat_fHigh income"   = "High income",
      "inscov_fPublic only"   = "Public only insurance",
      "inscov_fUninsured"     = "Uninsured",
      "n_ccsr"                = "Number of CCSR categories"
    ),
    Estimate = round(Estimate, 3),
    P_value  = add_sig(P_value)
  ) %>%
  select(Variable = Pretty, Estimate, P_value)

# Print clean table with kable
library(knitr)
kable(
  baseline_results,
  col.names = c("Variable", "Estimate", "P-value"),
  align = c("l", "c", "c"),
  row.names = FALSE
)



```

As is shown is the table, individuals `aged 45–64` and `65+` were significantly more likely to be high-cost compared with the reference age group. `Female` patients also exhibited slightly higher odds of being high-cost. Lack of insurance coverage (`Uninsured`) was another significant risk factor, highlighting the vulnerability of those without financial protection. Finally, the `number of CCSR condition categories`, our measure or multimorbidity, was significant and demonstrated the largest effect size.

<br>

### Model 2: Full model including major CCSR condition indicators

We extended the baseline model by adding binary indicators for the most common CCSR categories observed in the sample. We first summarized all condition records using both unweighted frequency counts and survey-weighted counts. 

```{r echo=FALSE, fig.width=5, fig.height=4}

ggplot(ccsr_top20,
       aes(x = reorder(ccsr_main, n),
           y = n)) +
  geom_col() +
  coord_flip() +
  labs(
    x = "CCSR category",
    y = "Number of condition records",
    title = "Top 20 most common CCSR condition categories (unweighted)"
  )+
  theme(plot.title = element_text(size = 10, hjust = 0))

ggplot(ccsr_w_top20,
       aes(x = reorder(ccsr_main, w_count),
           y = w_count)) +
  geom_col() +
  coord_flip() +
  labs(
    x = "CCSR category",
    y = "Weighted count of conditions",
    title = "Top 20 CCSR condition categories (weighted by PERWT23F)"
  )+
  theme(plot.title = element_text(size = 10, hjust = 0))
```

The two rankings were largely consistent, and we selected the union of the top conditions from both lists to ensure clinically relevant and high-prevalence categories were included. This process resulted in 11 CCSR binary indicators, each representing whether a person had at least one condition in that category. Including:

- **CIR007**: Essential hypertension
- **END010**: Disorders of lipid metabolism
- **MUS010**: Musculoskeletal pain  
- **END002**: Diabetes mellitus without complication 
- **MBD005**: Anxiety and fear-related disorders  
- **MBD002**: Depressive disorder  
- **END001**: Thyroid disorders
- **MUS006**: Osteoarthritis
- **DIG004**: Esophageal disorders  
- **RSP009**: Asthma
- **INJ031**: Allergic reactions


```{r echo=FALSE}
# full model
ccsr_vars <- c("CIR007","END010","MUS010","END002","MBD005",          "MBD002","END001","MUS006","DIG004","RSP009","INJ031")

full_formula <- update(
  baseline_formula,
  paste(". ~ . +", paste(ccsr_vars, collapse = " + "))
)

model_full <- svyglm(
  full_formula,
  design = des_model,
  family = quasibinomial()
)

```

`full_formula <- high_cost ~ age_cat4 + sex_f + race4 + povcat_f + inscov_f + n_ccsr`

```{r echo=FALSE}
coef_full <- summary(model_full)$coefficients

full_results <- data.frame(
  Variable_raw = rownames(coef_full),
  Estimate = coef_full[, "Estimate"],
  P_value = coef_full[, "Pr(>|t|)"]
) %>%
  filter(Variable_raw != "(Intercept)") %>%
  
  mutate(
    Variable = recode(
      Variable_raw,
      # Demographics
      "age_cat418-44"       = "Age 18–44",
      "age_cat445-64"       = "Age 45–64",
      "age_cat465+"         = "Age 65+",
      "sex_fFemale"         = "Female",
      "race4NH Black"       = "NH Black",
      "race4Hispanic"       = "Hispanic",
      "race4NH Asian/Other" = "NH Asian/Other",
      "povcat_fNear-poor"   = "Near-poor",
      "povcat_fLow income"  = "Low income",
      "povcat_fMiddle income" = "Middle income",
      "povcat_fHigh income" = "High income",
      "inscov_fPublic only" = "Public only insurance",
      "inscov_fUninsured"   = "Uninsured",
      "n_ccsr"              = "Number of CCSR categories",
      
      "CIR007" = "Essential hypertension",
      "END010" = "Disorders of lipid metabolism",
      "MUS010" = "Musculoskeletal pain",
      "END002" = "Diabetes mellitus (no complication)",
      "MBD005" = "Anxiety disorders",
      "MBD002" = "Depressive disorder",
      "END001" = "Thyroid disorders",
      "MUS006" = "Osteoarthritis",
      "DIG004" = "Esophageal disorders",
      "RSP009" = "Asthma",
      "INJ031" = "Allergic reactions"
    ),
    
    Estimate = round(Estimate, 3),
    P_display = round(P_value, 4),
    
    Stars = case_when(
      P_value < 0.001 ~ "***",
      P_value < 0.01  ~ "**",
      P_value < 0.05  ~ "*",
      TRUE ~ ""
    ),
    
    P_value_final = paste0(P_display, Stars)
  ) %>%
  
  select(Variable, Estimate, `P-value` = P_value_final)

kable(
  full_results,
  col.names = c("Variable", "Estimate", "P-value"),
  align = c("l","c","c"),
  row.names = FALSE
)

```

In the full model, disorders of lipid metabolism (`END010`), diabetes mellitus without complication (`END002`), depressive disorder (`MBD002`), anxiety disorders (`MBD005`), thyroid disorders (`END001`), and asthma (`RSP009`) show strong associations with higher healthcare spending.

Compared with `Model 1`, `Female` is no longer a significant predictors, while others ramain significant.

<br>

### Model 3: Selected model with significant predictors

```{r echo=FALSE}
# model with selected significant variables
selected_vars <- c(
  "age_cat4",
  "sex_f",
  "inscov_f",
  "n_ccsr",
  "END010","END002","MBD005","MBD002","END001","RSP009"
)

full_formula2 <- as.formula(
  paste("high_cost ~", paste(selected_vars, collapse = " + "))
)


model_selected <- svyglm(
  full_formula2,
  design = des_model,
  family = quasibinomial()
)

```

For `Model 3`, we only add the predictors that are significant in `Model 1` and `Model 2`, reducing model complexity. 

`selected_formula <- high_cost ~ age_cat4 + sex_f +  inscov_f + n_ccsr + END010 + END002 + MBD005 + MBD002 + END001 + RSP009`
  
```{r echo=FALSE}
# Extract coefficients
coef_tab3 <- summary(model_selected)$coefficients

selected_results <- data.frame(
  Variable = rownames(coef_tab3),
  Estimate = coef_tab3[, "Estimate"],
  P_value  = coef_tab3[, "Pr(>|t|)"]
) %>%
  filter(Variable != "(Intercept)") %>%
  mutate(
    Pretty = recode(
      Variable,
      "age_cat418-44" = "Age 18–44",
      "age_cat445-64" = "Age 45–64",
      "age_cat465+"   = "Age 65+",
      "sex_fFemale"   = "Female",

      "inscov_fPublic only" = "Public only insurance",
      "inscov_fUninsured"   = "Uninsured",

      "n_ccsr"   = "Number of CCSR categories",

      # CCSR conditions
      "END010" = "Disorders of lipid metabolism",
      "END002" = "Diabetes mellitus (no complication)",
      "MBD005" = "Anxiety disorders",
      "MBD002" = "Depressive disorder",
      "END001" = "Thyroid disorders",
      "RSP009" = "Asthma"
    ),
    Estimate = round(Estimate, 3),
    P_value  = round(P_value, 4),
    Sig = case_when(
      P_value < 0.001 ~ "***",
      P_value < 0.01  ~ "**",
      P_value < 0.05  ~ "*",
      P_value < 0.1   ~ ".",
      TRUE            ~ ""
    ),
    P_value = paste0(P_value, Sig)
  ) %>%
  select(Variable = Pretty, Estimate, P_value)

# Display table
library(knitr)
kable(
  selected_results,
  col.names = c("Variable", "Estimate", "P-value"),
  align = c("l", "c", "c"),
  row.names = FALSE
)

```

### Model Comparison

We compared the performance of the three fitted models using AIC. A lower AIC indicates a better trade-off between model fit and complexity.

```{r echo=FALSE}
aic_values <- data.frame(
  Model = c("Baseline model", "Full model", "Selected model"),
  AIC = c(
    as.numeric(AIC(model_baseline)["AIC"]),
    as.numeric(AIC(model_full)["AIC"]),
    as.numeric(AIC(model_selected)["AIC"])
  )
)

kable(
  aic_values,
  col.names = c("Model", "AIC"),
  digits = 2,
  align = "c",
  row.names = FALSE
)
```

Accordingly, the `Selected model` achieves the lowest AIC `r round(AIC(model_selected)["AIC"], 2)`. This suggests that adding clinically relevant CCSR indicators improves model fit, and further removing non-significant predictors yields a more efficient model without sacrificing performance.

```{r echo=FALSE}
# cv validation
cv_rmse <- function(formula, data, K = 5) {
  n <- nrow(data)
  folds <- sample(rep(1:K, length.out = n))
  
  rmse_vec <- numeric(K)
  
  for (k in 1:K) {
    train <- data[folds != k, ]
    test  <- data[folds == k, ]
    
    fit <- glm(formula, data = train, family = binomial())
    
  
    p_hat <- predict(fit, newdata = test, type = "response")
    
    # RMSE between predicted probability and actual 0/1
    rmse_vec[k] <- sqrt(mean((p_hat - test$high_cost)^2))
  }
  
  rmse_vec
}

```

```{r echo=FALSE}
set.seed(1234)
n_rep <- 100
K <- 5

df_cv <- fyc23_model %>%
  select(
    high_cost,
    age_cat4, sex_f, race4, povcat_f, inscov_f, n_ccsr,
    CIR007, END010, MUS010, END002, MBD005, MBD002, END001, MUS006, DIG004, RSP009, INJ031
  )%>%
  drop_na() %>%                            
  mutate(
    high_cost = as.numeric(high_cost),      
   
  )

cv_results <- map_dfr(1:n_rep, ~{
  tibble(
    model = "Baseline",
    rmse  = cv_rmse(baseline_formula, df_cv, K = K)
  ) %>%
    bind_rows(
      tibble(
        model = "Full",
        rmse  = cv_rmse(full_formula, df_cv, K = K)
      ),
      tibble(
        model = "Selected",
        rmse  = cv_rmse(full_formula2, df_cv, K = K)
      )
    )
})
```

To assess the predictive performance across different cohorts, we next perform repeated K-fold cross-validation on all three models and compare their RMSE distributions. We chose to repeat 100 times with K=`r K`.

```{r echo=FALSE}
ggplot(cv_results, aes(x = model, y = rmse)) +
  geom_violin(trim = FALSE, fill = NA, color = "lightblue") +
  geom_boxplot(width = 0.15, fill = "white", outlier.size = 0.5) +
  labs(
    x = NULL,
    y = "Cross-validated RMSE",
    title = "Cross-validated prediction error"
  ) +
  theme_minimal()
```

Across `r n_rep` repeated `r K`-fold cross-validations, all three models yielded very similar RMSE values. The selected model achieved the lowest average RMSE (≈0.2331). Although the improvement is modest, this suggests that adding a small set of targeted CCSR indicators contributes slightly better predictive accuracy than including all conditions or using demographics alone.

<br>

*The full, reproducible code used to implement the regression modeling and cross-validation procedures described above is provided below. Readers who are primarily interested in results may skip this section.*

<details>
<summary><strong>Click to show / hide full regression modeling code</strong></summary>

<br>

```{r}
## Regression
library(dplyr)
library(ggplot2)
library(tidyr)
library(purrr)
library(survey)

## ---- create multimorbidity (person_ccsr) ----
person_ccsr <- cond23_clean %>% 
  group_by(dupersid) %>% 
  summarise(
    n_ccsr = n_distinct(ccsr_main),   # number of distinct CCSR categories
    .groups = "drop"
  ) %>% 
  mutate(
    multi_morbidity = if_else(n_ccsr >= 3, 1, 0)  # threshold can be customized
  )

## ---- CCSR frequency (unweighted) ----
ccsr_counts <- cond23_clean %>% 
  count(ccsr_main, sort = TRUE)

head(ccsr_counts, 10)

ccsr_top20 <- ccsr_counts %>% 
  slice_max(n, n = 20)

ggplot(ccsr_top20,
       aes(x = reorder(ccsr_main, n),
           y = n)) +
  geom_col() +
  coord_flip() +
  labs(
    x = "CCSR category",
    y = "Number of condition records",
    title = "Top 20 most common CCSR condition categories (unweighted)"
  )

## ---- CCSR frequency (weighted) ----
ccsr_w_counts <- cond23_clean %>% 
  group_by(ccsr_main) %>% 
  summarise(
    w_count = sum(perwt23f, na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  arrange(desc(w_count))

ccsr_w_top20 <- ccsr_w_counts %>% 
  slice_max(w_count, n = 20)

ggplot(ccsr_w_top20,
       aes(x = reorder(ccsr_main, w_count),
           y = w_count)) +
  geom_col() +
  coord_flip() +
  labs(
    x = "CCSR category",
    y = "Weighted count of conditions",
    title = "Top 20 CCSR condition categories (weighted by PERWT23F)"
  )

## ---- compare top10 CCSR: unweighted vs weighted ----
data.frame(
  unweighted_top10 = ccsr_counts$ccsr_main[1:10],
  weighted_top10   = ccsr_w_counts$ccsr_main[1:10]
)

ccsr_union <- union(
  ccsr_counts$ccsr_main[1:10],
  ccsr_w_counts$ccsr_main[1:10]
)
ccsr_union

## ---- create binary disease indicators in person_ccsr ----
for (disease in ccsr_union) {
  var_name <- disease
  person_ccsr[[var_name]] <- ifelse(
    person_ccsr$dupersid %in% cond23_clean$dupersid[cond23_clean$ccsr_main == disease],
    1, 
    0
  )
}

## ---- merge to FYC file and define high_cost ----
fyc23_model <- fyc23_clean %>%
  left_join(person_ccsr, by = "dupersid") %>% 
  mutate(
    high_cost = ifelse(exp_group == "Top 5%", 1, 0)    # outcome: in top 5% vs others
  )

## ---- survey design object ----
des_model <- svydesign(
  ids     = ~varpsu,
  strata  = ~varstr,
  weights = ~perwt23f,
  data    = fyc23_model,
  nest    = TRUE
)

## ---- baseline model ----
baseline_formula <- high_cost ~ 
  age_cat4 + sex_f + race4 + povcat_f + inscov_f + n_ccsr

model_baseline <- svyglm(
  baseline_formula,
  design = des_model,
  family = quasibinomial()
)
summary(model_baseline)

## ---- full model with top CCSR indicators ----
ccsr_vars <- c(
  "CIR007","END010","MUS010","END002","MBD005",
  "MBD002","END001","MUS006","DIG004","RSP009","INJ031"
)

full_formula <- update(
  baseline_formula,
  paste(". ~ . +", paste(ccsr_vars, collapse = " + "))
)

model_full <- svyglm(
  full_formula,
  design = des_model,
  family = quasibinomial()
)
summary(model_full)

## ---- selected model (significant variables) ----
selected_vars <- c(
  "age_cat4",
  "sex_f",
  "inscov_f",
  "n_ccsr",
  "END010","END002","MBD005","MBD002","END001","RSP009"
)

full_formula2 <- as.formula(
  paste("high_cost ~", paste(selected_vars, collapse = " + "))
)

model_selected <- svyglm(
  full_formula2,
  design = des_model,
  family = quasibinomial()
)
summary(model_selected)

## ---- compare AIC ----
AIC(model_baseline)
AIC(model_full)
AIC(model_selected)

## ---- CV helper function (simple glm, no survey weights) ----
cv_rmse <- function(formula, data, K = 5) {
  n <- nrow(data)
  folds <- sample(rep(1:K, length.out = n))
  
  rmse_vec <- numeric(K)
  
  for (k in 1:K) {
    train <- data[folds != k, ]
    test  <- data[folds == k, ]
    
    fit <- glm(formula, data = train, family = binomial())
    
    p_hat <- predict(fit, newdata = test, type = "response")
    rmse_vec[k] <- sqrt(mean((p_hat - test$high_cost)^2))
  }
  
  rmse_vec
}

## ---- prepare data for CV ----
set.seed(1234)
n_rep <- 100
K <- 5

df_cv <- fyc23_model %>%
  select(
    high_cost,
    age_cat4, sex_f, race4, povcat_f, inscov_f, n_ccsr,
    CIR007, END010, MUS010, END002, MBD005, MBD002, END001, MUS006, DIG004, RSP009, INJ031
  ) %>%
  drop_na() %>%                            
  mutate(
    high_cost = as.numeric(high_cost)
  )

## ---- run CV for three models ----
cv_results <- map_dfr(1:n_rep, ~{
  tibble(
    model = "Baseline",
    rmse  = cv_rmse(baseline_formula, df_cv, K = K)
  ) %>%
    bind_rows(
      tibble(
        model = "Full",
        rmse  = cv_rmse(full_formula, df_cv, K = K)
      ),
      tibble(
        model = "Selected",
        rmse  = cv_rmse(full_formula2, df_cv, K = K)
      )
    )
})

## ---- summarise CV results ----
cv_summary <- cv_results %>%
  group_by(model) %>%
  summarise(mean_rmse = mean(rmse)) %>%
  arrange(model)

cv_summary

## ---- plot CV RMSE ----
ggplot(cv_results, aes(x = model, y = rmse)) +
  geom_violin(trim = FALSE, fill = NA, color = "lightblue") +
  geom_boxplot(width = 0.15, fill = "white", outlier.size = 0.5) +
  labs(
    x = NULL,
    y = "Cross-validated RMSE",
    title = "Cross-validated prediction error for three models"
  ) +
  theme_minimal()

```

</details>

***
## Discussion
Our findings indicate that a parsimonious set of demographic and clinical predictors can meaningfully distinguish high cost patients in the 2023 MEPS sample. The final model incorporates age, insurance status, multimorbidity burden, and six key CCSR based condition indicators, suggesting that a relatively small and interpretable set of health and socioeconomic characteristics is sufficient to capture much of the observable contrast between high and lower cost individuals. Although overall predictive performance is modest, which is typical for rare and highly variable cost outcomes in population based survey data, the model nonetheless provides actionable signal that may support earlier identification of high cost patients and inform the design and targeting of care management or cost containment interventions in value based care settings.


